{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, RobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import pandas as pd\n",
    "from torch.nn.functional import softmax\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Seeing people have so much junk chasing for th...\n",
       "1                        Once he's dead, they're easy.\n",
       "2                                       \"Pucking hell.\n",
       "3                     some fools to not pay his bills.\n",
       "4                         What are you doing on stage?\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = pd.read_csv(\"../data/interim/predictions.csv\", index_col=0)\n",
    "predicted = predicted[\"0\"]\n",
    "\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568822</th>\n",
       "      <td>Hearing people have so much junk vying for the...</td>\n",
       "      <td>hearing people have a lot of unsolicited atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322428</th>\n",
       "      <td>Once he's dead, they'il be easy.</td>\n",
       "      <td>when he's gone, we'll take them easy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17886</th>\n",
       "      <td>\"Fucking hell.</td>\n",
       "      <td>\"oh, my God.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446836</th>\n",
       "      <td>some fool not to pay his bill.</td>\n",
       "      <td>A looser who can't pay his bill.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>what are you doing on stage, fool?</td>\n",
       "      <td>What are you doing on the stage, weirdo?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reference  \\\n",
       "568822  Hearing people have so much junk vying for the...   \n",
       "322428                   Once he's dead, they'il be easy.   \n",
       "17886                                      \"Fucking hell.   \n",
       "446836                     some fool not to pay his bill.   \n",
       "56045                  what are you doing on stage, fool?   \n",
       "\n",
       "                                              translation  \n",
       "568822  hearing people have a lot of unsolicited atten...  \n",
       "322428              when he's gone, we'll take them easy.  \n",
       "17886                                        \"oh, my God.  \n",
       "446836                   A looser who can't pay his bill.  \n",
       "56045            What are you doing on the stage, weirdo?  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../data/interim/test.csv\", index_col=0)\n",
    "reference = test[\"reference\"].head(len(predicted))\n",
    "translation = test[\"translation\"].head(len(predicted))\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toxicity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "toxicity_classifier = RobertaForSequenceClassification.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')\n",
    "toxicity_tokenizer =  RobertaTokenizer.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31748/361774536.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0001319961593253538"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_toxicity(text):\n",
    "    encoded = toxicity_tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "    logits = toxicity_classifier(encoded)[0][0]\n",
    "    probs = softmax(logits)\n",
    "\n",
    "    return probs[1].item()\n",
    "\n",
    "\n",
    "calculate_toxicity(\"oh, my God.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31748/361774536.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.211716\n",
       "1       0.954745\n",
       "2       0.971003\n",
       "3       0.998018\n",
       "4       0.000042\n",
       "          ...   \n",
       "2995    0.993415\n",
       "2996    0.012222\n",
       "2997    0.986335\n",
       "2998    0.000042\n",
       "2999    0.000064\n",
       "Name: 0, Length: 3000, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_toxicity = predicted.apply(calculate_toxicity)\n",
    "translation_toxicity = translation.apply(calculate_toxicity)\n",
    "reference_toxicity = reference.apply(calculate_toxicity)\n",
    "\n",
    "predicted_toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29959127625582915"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_toxicity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10090807241426349"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_toxicity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226643118323991"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_toxicity.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean toxicity score dropped from 0.82 to 0.3, though it is not reached the mean of translation toxicity (labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 8.47MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.59MB/s]\n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 19.5MB/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 1.74MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 170kB/s]\n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 359kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:14<00:00, 6.32MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 182kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 208kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.09MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 2.48MB/s]\n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 79.9MB/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 910kB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 2.25MB/s]\n"
     ]
    }
   ],
   "source": [
    "similarity_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text):\n",
    "    return similarity_model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_embeddings = predicted.apply(embed)\n",
    "translation_embeddings = translation.apply(embed)\n",
    "reference_embeddings = reference.apply(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6416714"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean predicted and translation similarity\n",
    "np.array(list(predicted_embeddings.values * translation_embeddings.values)).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6998071"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean reference and translation similarity\n",
    "np.array(list(reference_embeddings.values * translation_embeddings.values)).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean similarity of model outputs does not dropped significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with baseline \n",
    "(from here: https://github.com/ramsrigouthamg/Paraphrase-any-question-with-T5-Text-To-Text-Transfer-Transformer-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tokenizer = T5Tokenizer.from_pretrained(\"ramsrigouthamg/t5_paraphraser\")\n",
    "\n",
    "baseline_model = T5ForConditionalGeneration.from_pretrained(\"ramsrigouthamg/t5_paraphraser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_baseline(text):\n",
    "    generated = baseline_model.generate(\n",
    "            baseline_tokenizer.encode(\"paraphrase: \" + text, return_tensors=\"pt\"),\n",
    "            num_beams=10, num_return_sequences=1, max_length=64\n",
    "        )\n",
    "    \n",
    "    return baseline_tokenizer.decode(generated[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568822    Why do people have so much junk vying for thei...\n",
       "322428                     Once he's dead, they'll be easy.\n",
       "17886                                        \"Fucking Hell.\n",
       "446836                       Some fool not to pay his bill.\n",
       "56045                          What are you doing on stage?\n",
       "                                ...                        \n",
       "154862         Or maybe 'cause you're still fucking Harold.\n",
       "370990    I hate this place. I hate this place. I hate t...\n",
       "360849                   I'll bite her into Bobby's belt. \"\n",
       "432350                              Get your ass back here!\n",
       "184367    I knew you were full of shit when you said you...\n",
       "Name: reference, Length: 3000, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_predictions = reference.apply(predict_baseline)\n",
    "\n",
    "baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31748/361774536.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7648516015903781"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_toxicity = baseline_predictions.apply(calculate_toxicity)\n",
    "\n",
    "baseline_toxicity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6797197"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_embeded = baseline_predictions.apply(embed)\n",
    "\n",
    "# Mean baseline prediction and translation similarity\n",
    "np.array(list(baseline_embeded.values * translation_embeddings.values)).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed model removes toxicity better than the baseline, though baseline preserves more similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
