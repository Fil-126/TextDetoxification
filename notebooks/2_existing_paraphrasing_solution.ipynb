{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existing solution for paraphrasing\n",
    "\n",
    "Found here: https://github.com/ramsrigouthamg/Paraphrase-any-question-with-T5-Text-To-Text-Transfer-Transformer-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fil126/Desktop/Study/PMLDL/Assignment1/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fil126/Desktop/Study/PMLDL/Assignment1/venv/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 1.88MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 892M/892M [02:31<00:00, 5.88MB/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "model_path = \"ramsrigouthamg/t5_paraphraser\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"could you keep your mouth shut, Miss Opulent?\"\n",
    "\n",
    "generated = model.generate(\n",
    "            tokenizer.encode(\"paraphrase: \" + sent, return_tensors=\"pt\"),\n",
    "            num_beams=10, num_return_sequences=5, max_length=64\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you keep your mouth shut, Miss Opulent?\n",
      "\n",
      "Can you keep your mouth shut, Miss Opulent?\n",
      "\n",
      "Could you keep your mouth closed, Miss Opulent?\n",
      "\n",
      "Could you keep your mouth shut Miss Opulent?\n",
      "\n",
      "Miss Opulent, could you keep your mouth shut?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for generated_sentence in generated:\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            generated_sentence,\n",
    "            skip_special_tokens=True\n",
    "        ) + \"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to use this model as the base and fine-tune it for detoxification purposes.\n",
    "\n",
    "Also, this model can be used as a baseline solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
